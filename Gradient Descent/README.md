ğŸ“‰ Gradient Descent from Scratch
A hands-on and visual deep dive into one of the most essential optimization algorithms in machine learning â€” Gradient Descent, built using just Python and NumPy.

ğŸ§  What You'll Learn
âœ… Manual implementation of gradient descent
âœ… Deriving gradients from scratch
âœ… Linear regression using only NumPy
âœ… Visualizing training and convergence

ğŸ“¸ Screenshots & Results
ğŸ” Training Progress â€” Loss Over Iterations
Shows how the Mean Squared Error reduces over time as the model learns.
<img width="1372" height="499" alt="Loss Curve" src="https://github.com/user-attachments/assets/a7630528-0b2a-456c-967a-b397b57be13e" />

ğŸ“ˆ Final Regression Line
The line fitted to the data points using learned weights and bias.
<img width="1372" height="499" alt="Regression Line" src="https://github.com/user-attachments/assets/8eee552c-af8f-4bbb-99fd-de130b7a8c3e" />

ğŸ§® Sample Output Printout
Model output showing final values of loss, weights, and bias after training.
<img width="1396" height="388" alt="Console Output" src="https://github.com/user-attachments/assets/699ea094-3522-4c03-962f-15d71142ab35" />

ğŸ“ Project Structure
bash
Copy
Edit
ğŸ“¦ GradientDescent
 â”£ ğŸ“œ GradientDescent.ipynb    # Main notebook with logic & plots
 â”— ğŸ“„ README.md                 # This file
âš™ï¸ Tech Stack
ğŸ Python 3.x

ğŸ§® NumPy

ğŸ“Š Matplotlib

ğŸ““ Jupyter Notebook

ğŸš€ How to Run
bash
Copy
Edit
git clone https://github.com/Abdulwahab-ml/GradientDescent.git
cd GradientDescent
jupyter notebook GradientDescent.ipynb
ğŸ’¡ Ideas to Extend
Add multiple feature support

Experiment with different learning rates

Compare with scikit-learn for validation

ğŸ‘¤ Author
Abdul Wahab
ğŸŒ± Learning Machine Learning from scratch
ğŸ”— @abdulwahab-ml
